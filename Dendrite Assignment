{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8676388,"sourceType":"datasetVersion","datasetId":5200741},{"sourceId":8676406,"sourceType":"datasetVersion","datasetId":5200755}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport csv\nimport pandas as pd\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:43:07.869037Z","iopub.execute_input":"2024-06-13T08:43:07.871176Z","iopub.status.idle":"2024-06-13T08:43:08.097244Z","shell.execute_reply.started":"2024-06-13T08:43:07.871112Z","shell.execute_reply":"2024-06-13T08:43:08.095343Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# !pip install striprtf","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:39:55.009590Z","iopub.execute_input":"2024-06-13T08:39:55.010230Z","iopub.status.idle":"2024-06-13T08:40:15.149148Z","shell.execute_reply.started":"2024-06-13T08:39:55.010179Z","shell.execute_reply":"2024-06-13T08:40:15.147156Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting striprtf\n  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\nDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\nInstalling collected packages: striprtf\nSuccessfully installed striprtf-0.0.26\n","output_type":"stream"}]},{"cell_type":"code","source":"# import json\n# from striprtf.striprtf import rtf_to_text\n\n# with open('/kaggle/input/jason-parsing/algoparams_from_ui.json.rtf') as json_file:\n#     content = json_file.read()\n#     file = rtf_to_text(content)\n# print()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:40:15.151922Z","iopub.execute_input":"2024-06-13T08:40:15.152506Z","iopub.status.idle":"2024-06-13T08:40:15.220389Z","shell.execute_reply.started":"2024-06-13T08:40:15.152449Z","shell.execute_reply":"2024-06-13T08:40:15.218885Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pypandoc","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:40:47.849780Z","iopub.execute_input":"2024-06-13T08:40:47.850359Z","iopub.status.idle":"2024-06-13T08:41:07.014312Z","shell.execute_reply.started":"2024-06-13T08:40:47.850315Z","shell.execute_reply":"2024-06-13T08:41:07.012532Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting pypandoc\n  Downloading pypandoc-1.13-py3-none-any.whl.metadata (16 kB)\nDownloading pypandoc-1.13-py3-none-any.whl (21 kB)\nInstalling collected packages: pypandoc\nSuccessfully installed pypandoc-1.13\n","output_type":"stream"}]},{"cell_type":"code","source":"import pypandoc\n\ndef convert_rtf_to_text(file_path):\n    output = pypandoc.convert_file(json_file_path, 'plain', format='rtf')\n    return output\n\n# Example usage\njson_file_path = '/kaggle/input/jason-parsing/algoparams_from_ui.json.rtf'\ntext = convert_rtf_to_text(json_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T10:37:23.203241Z","iopub.execute_input":"2024-06-13T10:37:23.203875Z","iopub.status.idle":"2024-06-13T10:37:23.385467Z","shell.execute_reply.started":"2024-06-13T10:37:23.203835Z","shell.execute_reply":"2024-06-13T10:37:23.383440Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"stripped_text = text.replace('\\n', '')\ntext = stripped_text.replace(' ', '')\nconstraint_dict = json.loads(text)\nprint(type(constraint_dict))","metadata":{"execution":{"iopub.status.busy":"2024-06-13T10:37:27.764871Z","iopub.execute_input":"2024-06-13T10:37:27.765526Z","iopub.status.idle":"2024-06-13T10:37:27.775714Z","shell.execute_reply.started":"2024-06-13T10:37:27.765479Z","shell.execute_reply":"2024-06-13T10:37:27.773720Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"<class 'dict'>\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataLoader:\n    def __init__(self, data_file_path):\n        self.data_file_path = data_file_path\n        self.data = None\n        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n\n    def load_data(self):\n        # Load the dataset\n        self.data = pd.read_csv(self.data_file_path)\n        \n        # Split the dataset into features and target variable\n        X = self.data.drop(columns='species')  # Assuming 'species' is the target column\n        y = self.data['species']\n        \n        # Split the dataset into training and testing sets\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        print(\"Data loaded successfully\")\n        \n#     def create_imputes(self):\n        \n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T10:38:29.444522Z","iopub.execute_input":"2024-06-13T10:38:29.445032Z","iopub.status.idle":"2024-06-13T10:38:29.456430Z","shell.execute_reply.started":"2024-06-13T10:38:29.444996Z","shell.execute_reply":"2024-06-13T10:38:29.454828Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# data = DataLoader('/kaggle/input/iris-dataset-dendrite/iris.csv')\n# data.load_data()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:01:22.726270Z","iopub.execute_input":"2024-06-13T07:01:22.726690Z","iopub.status.idle":"2024-06-13T07:01:22.732107Z","shell.execute_reply.started":"2024-06-13T07:01:22.726656Z","shell.execute_reply":"2024-06-13T07:01:22.730604Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class PipelineData(DataLoader):\n    def __init__(self, data_file_path):\n        super().__init__(data_file_path)\n        self.pipeline_data = Pipeline([])\n        print(\"Data Pipeline Created\")\n        \n    def feature_handling(self):\n        \n        # Delete columns if is_selected is false\n        if(constraint_dict['design_state_data']['feature_handling']['sepal_length']['is_selected'] == False):\n            print(\"False\")\n            super().X_train = super().X_train.drop('sepal_length')\n            super().X_test = super().X_test.drop('sepal_length')\n        \n        if(constraint_dict['design_state_data']['feature_handling']['sepal_length']['is_selected'] == False):\n            print(\"False\")\n            super().X_train = super().X_train.drop('sepal_length')\n            super().X_test = super().X_test.drop('sepal_length')\n            \n        if(constraint_dict['design_state_data']['feature_handling']['sepal_length']['is_selected'] == False):\n            print(\"False\")\n            super().X_train = super().X_train.drop('sepal_length')\n            super().X_test = super().X_test.drop('sepal_length')\n            \n        if(constraint_dict['design_state_data']['feature_handling']['sepal_length']['is_selected'] == False):\n            print(\"False\")\n            super().X_train = super().X_train.drop('sepal_length')\n            super().X_test = super().X_test.drop('sepal_length')\n            \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-13T10:38:32.336051Z","iopub.execute_input":"2024-06-13T10:38:32.336723Z","iopub.status.idle":"2024-06-13T10:38:32.360619Z","shell.execute_reply.started":"2024-06-13T10:38:32.336681Z","shell.execute_reply":"2024-06-13T10:38:32.357654Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# pipelineData = PipelineData('/kaggle/input/iris-dataset-dendrite/iris.csv')\n# pipelineData.load_data()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:49:52.878766Z","iopub.execute_input":"2024-06-13T08:49:52.879524Z","iopub.status.idle":"2024-06-13T08:49:52.899205Z","shell.execute_reply.started":"2024-06-13T08:49:52.879460Z","shell.execute_reply":"2024-06-13T08:49:52.897457Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Data loaded successfully\n","output_type":"stream"}]},{"cell_type":"code","source":"class PipelineModel(PipelineData):\n    def __init__(self, data_file_path):\n        super().__init__(data_file_path)\n    \n    \n    def load_feature_handling():\n        super().load_data()\n        self.pipeline_model = Pipeline([])\n        print(\"Data and Model Pipeline created successfully\")\n#         super().feature_handling()\n        \n    \n    \n        \n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T10:38:34.753276Z","iopub.execute_input":"2024-06-13T10:38:34.755053Z","iopub.status.idle":"2024-06-13T10:38:34.763299Z","shell.execute_reply.started":"2024-06-13T10:38:34.755000Z","shell.execute_reply":"2024-06-13T10:38:34.761604Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"\nmodel_pipe = PipelineModel('/kaggle/input/iris-dataset-dendrite/iris.csv')\nmodel_pipe.X_train","metadata":{"execution":{"iopub.status.busy":"2024-06-13T10:39:34.630708Z","iopub.execute_input":"2024-06-13T10:39:34.631265Z","iopub.status.idle":"2024-06-13T10:39:34.639468Z","shell.execute_reply.started":"2024-06-13T10:39:34.631229Z","shell.execute_reply":"2024-06-13T10:39:34.637759Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"Data Pipeline Created\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model_pipe.X_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T10:39:38.078856Z","iopub.execute_input":"2024-06-13T10:39:38.079410Z","iopub.status.idle":"2024-06-13T10:39:38.087276Z","shell.execute_reply.started":"2024-06-13T10:39:38.079347Z","shell.execute_reply":"2024-06-13T10:39:38.085536Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}